= Масштабирование БД

- Репликация
- Шардинг
- Партиционирование

== Репликация
Синхронное или асинхронное копирование данных между несколькими серверами. Ведущие серверы часто называют мастерами (master), а ведомые серверы — слэйвами (slaves), иногда используются и другие названия — лидер и фолловеры (leader & followers), праймари и реплики (primary & replicas). Один ведущий узел (мастер, лидер, праймари) принимает запросы как на запись, так и на чтение, а ведомые (реплики, слейвы или фолловеры) синхронизируются с ним и обслуживают только запросы на чтение.
Репликация на серверах СУБД PostgreSQL бывает двух видов: физическая и логическая.

=== Физическая репликация
При физической репликации на сервер реплики передается поток WAL записей (журнал предзаписи транзакций). Одним из основных достоинств физической репликации является простота в конфигурировании и использовании, так как используется простое побайтовое копирование с одного сервера на другой.
Но у физических репликаций есть и свои недостатки. По аналогии с физическим бэкапом здесь также требуются одинаковые версии PostgreSQL и операционной системы.
При этом, также должны быть идентичны в том числе и аппаратные компоненты, такие как архитектура процессора. При физических бэкапах возможна репликация только всего кластера, на подчиненном инстансе нельзя создать никакую отдельную таблицу, даже временную. Полная идентичность основному серверу.

=== Логическая репликация
Логическая репликация работает по принципу подписки. Мастер сервер выступает в роли поставщика, который публикует изменения, происходящие в базе, а серверы реплики, выступающие в роли подписчиков получают и применяют эти изменения у себя.
Логическая репликация имеет ряд преимуществ перед физической. Прежде всего, это независимость от используемых непосредственно на серверах форматов хранения данных. То есть, мастер и слейв могут иметь различные представления данных на диске, разные ОС и архитектуры.
Также плюсом является возможность выборочной репликации отдельных объектов кластера,
в результате мы можем снизить нагрузку на сеть, так как при логической репликации объем передаваемых данных меньше.

== Шардинг (горизонтальный)
Прием, который позволяет распределять данные между разными физическими серверами. Процесс шардинга предполагает разнесение данных между отдельными шардами на основе некого ключа шардинга. Связанные одинаковым значением ключа шардинга сущности группируются в набор данных по заданному ключу, а этот набор хранится в пределах одного физического шарда. Это существенно облегчает обработку данных. По сути, это горизонтальное разделение данных между независимыми базами (шардами), которые могут находиться на разных серверах.
Стратегии шардирования могут отличаться в зависимости от задач:

- Ключевой шардинг (Key-Based) — данные распределяются по шардам посредством хэш‑функции или через остаток от деления (например, user_id % N)
- Диапазонный шардинг (Range-Based) — шарды хранят данные из определенных диапазонов (например, пользователи A–M, N–Z)
- Географический шардинг — данные хранятся ближе к пользователям (шард для РФ, шард для ЕС, шард для США).

== Партиционирование (вертикальный шардинг)
Разбиение таблиц, содержащих большое количество записей,
на логические части по некоторому критерию, ключу секционирования (зачастую дата).
Партицирование применяется на одном инстансе — это тот же самый инстанс БД, где у вас лежала бы большая толстая таблица,
но мы ее раздробили на мелкие части.
В postgres:

. по диапазонам
. по списку (явно указывающему какие значения должны относится к каждой секции)
. по хэшу

=== Декларативное/ Ч-з наследование
==== Преимущества секционированных таблиц
- Существенное увеличение скорости индексного доступа на чтение, при условии наличия в запросе условия (ON, WHERE) по ключу секционирования.
- Увеличение скорости последовательного чтения, при условии наличия в запросе условия (ON, WHERE) по ключу секционирования.
Даже если ваш индекс не селективен, вы получите выигрыш за счет чтения только тех секций, которые попадут под условие
и последовательное сканирование этой секции может выполняться гораздо быстрее, чем случайный доступ по индексу к данным,
разбросанным по всей таблице.
- Увеличение скорости модифицирующих операций за счет времени на обновление индексов.
Сами индексы создаются отдельно на каждую секцию, что существенно сокращает их размер.
- Возможность отключать те секции, которые больше не нужны бизнесу. За счет этого решается вопрос "удаления" ("охлаждения") неиспользуемых данных
или их переноса на более медленные носители. Массовую загрузку и удаление данных можно осуществлять, добавляя и удаляя секции, что тоже оптимальнее,
чем выполнять это на всей огромной таблице (с последующими расходами на ее vacuum).
- Партиционирование таблиц делит весь объем операций по обработке данных на несколько независимых
и параллельно выполняющихся потоков, что существенно ускоряет работу с БД.

В случаях, когда в таблице часто выполняются запросы, которые не содержат ключа секционирования и затрагивающие все разделы,
секционирование может приводить к снижению производительности доступа в несколько раз.

==== Показания к применению
Партиционировать стоит те таблицы, размер которых превышает объем оперативной памяти сервера более, чем в 3 раза (грубый критерий оценки).
Однако, в общем случае, если таблица превысила размер 50-100GB стоит уже задуматься о ее партиционировании.

==== pg_partman
Партиционирование через pg_partman:

. создаем партиционированную родительскую таблицу
. создаем неуникальные индексы для нее
. создаем template-таблицу для уникальных индексов
. добавляем ей уник. индексы
. задаем настройки партиционирования SELECT partman.create_parent('public.part_table_1',
                                                                  'date_created',
                                                                  'native',
                                                                  'daily',
                                                                  p_start_partition := '2023-01-23',
                                                                  p_template_table := 'public.part_table_1_template',
                                                                  p_premake := 3)
. проверяем SELECT * FROM partman.part_config where parent_table = 'public.part_table_1';
. заполняем имеющимися данными из непартиционированной таблицы:
COPY () TO и COPY FROM
CALL partman.partition_data_proc()
INSERT INTO original_table
SELECT * FROM old_nonpartitioned_table)

* Все non-unique индексы родительской таблицы parent будут создаваться автоматом и в дочерних (для PG11+)
А вот для уникальных (Primary key, Unique constraint) поможет template-таблица.
